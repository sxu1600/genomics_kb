{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d467732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9970239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the input tsv file\n",
    "df = pd.read_csv('data/database/01-Jan-2023-ClinicalEvidenceSummaries.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1cc610",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811df20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preferred term for 'acute Monoblastic Leukemia (FAB M5a)' is 'Acute Monoblastic Leukemia'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "430                      Breast Carcinoma\n",
       "431                      Breast Carcinoma\n",
       "432                  Mantle Cell Lymphoma\n",
       "433          Chronic Lymphocytic Leukemia\n",
       "434                   Plasma Cell Myeloma\n",
       "435    Thyroid Gland Follicular Carcinoma\n",
       "436    Thyroid Gland Follicular Carcinoma\n",
       "437                  Renal Cell Carcinoma\n",
       "438                      Breast Carcinoma\n",
       "439                      Breast Carcinoma\n",
       "Name: disease, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove NA\n",
    "df = df.fillna('').iloc[430:440]\n",
    "\n",
    "# replace synonyms\n",
    "%run 'helper_funcs.ipynb'\n",
    "df['disease'] = df['disease'].apply(find_preferred_term_by_synonym)\n",
    "df['disease']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efffaa",
   "metadata": {},
   "source": [
    "## Update output/disease_node.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ca66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialize disease_node.csv\n",
    "disease_node_path = 'output/disease_node.csv'\n",
    "disease_node_df = pd.read_csv(disease_node_path) if os.path.isfile(disease_node_path) else pd.DataFrame(columns=['disease_id', 'disease_name', 'source'])\n",
    "\n",
    "# Update diseases\n",
    "df['disease_lower'] = df['disease'].str.lower()\n",
    "disease_node_df['disease_name_lower'] = disease_node_df['disease_name'].str.lower()\n",
    "# Find new diseases not in disease_node_df\n",
    "new_diseases = ~df['disease_lower'].isin(disease_node_df['disease_name_lower'])\n",
    "new_diseases_df = df.loc[new_diseases, 'disease'].drop_duplicates().reset_index(drop=True)\n",
    "new_diseases_df = pd.DataFrame({\n",
    "    'disease_id': range(disease_node_df['disease_id'].max() + 1, disease_node_df['disease_id'].max() + 1 + len(new_diseases_df)),\n",
    "    'disease_name': new_diseases_df,\n",
    "    'source': 'civic'\n",
    "})\n",
    "disease_node_df = pd.concat([disease_node_df, new_diseases_df], ignore_index=True).drop(columns=['disease_name_lower'])\n",
    "disease_node_df.to_csv(disease_node_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09164246",
   "metadata": {},
   "source": [
    "## Create or update output/snv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a535674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/796322992.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  snv_df = snv_df.append(new_record, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Load or initialize snv.csv\n",
    "snv_path = 'output/snv.csv'\n",
    "if os.path.isfile(snv_path):\n",
    "    snv_df = pd.read_csv(snv_path)\n",
    "    # Ensure that new columns exist in the dataframe\n",
    "    if 'variant_summary' not in snv_df.columns:\n",
    "        snv_df['variant_summary'] = ''\n",
    "    if 'variant_origin' not in snv_df.columns:\n",
    "        snv_df['variant_origin'] = ''\n",
    "else:\n",
    "    # Define columns including new ones\n",
    "    snv_df = pd.DataFrame(columns=['gene', 'variant', 'snv_id', 'source', 'variant_summary', 'variant_origin'])\n",
    "\n",
    "# Create a lowercase gene-variant combination column for case-insensitive comparison\n",
    "df['gene_variant'] = df['gene'].str.lower() + '_' + df['variant'].str.lower()\n",
    "snv_df['gene_variant'] = snv_df['gene'].str.lower() + '_' + snv_df['variant'].str.lower()\n",
    "\n",
    "# Update existing records\n",
    "for idx, row in df.iterrows():\n",
    "    match = snv_df['gene_variant'] == row['gene_variant']\n",
    "    if match.any():\n",
    "        snv_df.loc[match, 'variant_summary'] = row['variant_summary']\n",
    "        snv_df.loc[match, 'variant_origin'] = row['variant_origin']\n",
    "        snv_df.loc[match, 'source'] = snv_df.loc[match, 'source'].apply(lambda x: x if 'civic' in x else f\"{x}+civic\")\n",
    "\n",
    "# Add new records\n",
    "new_snv_records = df.loc[~df['gene_variant'].isin(snv_df['gene_variant'])]\n",
    "for _, new_row in new_snv_records.iterrows():\n",
    "    next_snv_id = snv_df['snv_id'].max() + 1\n",
    "    new_record = {\n",
    "        'gene': new_row['gene'],\n",
    "        'variant': new_row['variant'],\n",
    "        'snv_id': next_snv_id,\n",
    "        'source': 'civic',  # Assign the source for the new entry\n",
    "        'variant_summary': new_row['variant_summary'],\n",
    "        'variant_origin': new_row['variant_origin'],\n",
    "        'gene_variant': new_row['gene_variant']  # Include the gene_variant for later removal\n",
    "    }\n",
    "    snv_df = snv_df.append(new_record, ignore_index=True)\n",
    "\n",
    "# Drop the temporary 'gene_variant' column used for matching\n",
    "snv_df.drop(columns=['gene_variant'], inplace=True)\n",
    "\n",
    "# Save the updated snv_df to the CSV\n",
    "snv_df.to_csv(snv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7660996",
   "metadata": {},
   "source": [
    "## Create or update output/drug.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78a3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialize drug.csv\n",
    "drug_path = 'output/drug.csv'\n",
    "if os.path.isfile(drug_path):\n",
    "    drug_df = pd.read_csv(drug_path)\n",
    "    # Ensure that new columns exist in the dataframe\n",
    "    if 'drug_interaction_type' not in drug_df.columns:\n",
    "        drug_df['drug_interaction_type'] = ''\n",
    "else:\n",
    "    # Define columns including new ones\n",
    "    drug_df = pd.DataFrame(columns=['drug_name', 'drug_family', 'drug_status', 'evidencel_level', 'drug_id', 'source', 'drug_interaction_type'])\n",
    "\n",
    "# Create a lowercase drug names column for case-insensitive comparison\n",
    "df['drugs_lower'] = df['drugs'].str.lower()\n",
    "drug_df['drug_name_lower'] = drug_df['drug_name'].str.lower()\n",
    "\n",
    "# Update existing records with 'drug_interaction_type' and 'source'\n",
    "for idx, row in df.iterrows():\n",
    "    match = drug_df['drug_name_lower'] == row['drugs_lower']\n",
    "    if match.any():\n",
    "        # Update the 'drug_interaction_type' for existing drugs\n",
    "        drug_df.loc[match, 'drug_interaction_type'] = row['drug_interaction_type']\n",
    "        # Update source by appending '+civic' if necessary\n",
    "        drug_df.loc[match, 'source'] = drug_df.loc[match, 'source'].astype(str).apply(lambda x: f\"{x}+civic\" if 'civic' not in x else x)\n",
    "\n",
    "# Find new drugs not in drug_df\n",
    "new_drugs = ~df['drugs_lower'].isin(drug_df['drug_name_lower'])\n",
    "if new_drugs.any():\n",
    "    # Drop duplicates based on the 'drugs' column, which is the original column name\n",
    "    new_drugs_df = df.loc[new_drugs, ['drugs', 'drug_interaction_type']].drop_duplicates(subset=['drugs'])\n",
    "    new_drugs_df['drug_id'] = range(drug_df['drug_id'].max() + 1, drug_df['drug_id'].max() + 1 + len(new_drugs_df))\n",
    "    new_drugs_df['source'] = 'civic'\n",
    "    # Rename columns to match those in drug_df\n",
    "    new_drugs_df.rename(columns={'drugs': 'drug_name'}, inplace=True)\n",
    "    # Select only the relevant columns to append to drug_df\n",
    "    new_drugs_df = new_drugs_df[['drug_id', 'drug_name', 'source', 'drug_interaction_type']]\n",
    "    # Append the new entries\n",
    "    drug_df = pd.concat([drug_df, new_drugs_df], ignore_index=True)\n",
    "\n",
    "# Now, update 'drug_interaction_type' for existing records, and concatenate '+civic' if necessary\n",
    "for idx, row in df.iterrows():\n",
    "    drug_idx = drug_df['drug_name'].str.lower() == row['drugs'].lower()\n",
    "    if drug_idx.any():\n",
    "        drug_df.loc[drug_idx, 'drug_interaction_type'] = row['drug_interaction_type']\n",
    "        drug_df.loc[drug_idx, 'source'] = drug_df.loc[drug_idx, 'source'].apply(lambda x: x if 'civic' in x else f\"{x}+civic\")\n",
    "\n",
    "# Save the updated drug_df to the CSV\n",
    "drug_df.drop(columns=['drug_name_lower'], inplace=True)\n",
    "drug_df.to_csv(drug_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27597d1",
   "metadata": {},
   "source": [
    "## Create or update output/statement.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2808a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n",
      "/var/folders/n0/4sr1d2x93cb_dvn79mm6hrdc0000gn/T/ipykernel_60481/1538898609.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statement_df = statement_df.append(new_entry, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Check if statement.csv exists and create or append to it\n",
    "statement_file_path = 'output/statement.csv'\n",
    "\n",
    "if os.path.isfile(statement_file_path):\n",
    "    statement_df = pd.read_csv(statement_file_path)\n",
    "    # Ensure that the 'source' column is of type string\n",
    "    statement_df['source'] = statement_df['source'].astype(str)\n",
    "else:\n",
    "    statement_df = pd.DataFrame(columns=['statement_id', 'drug_id', 'disease_id', 'snv_id', 'association', 'source', 'clinical_significance'])\n",
    "\n",
    "# Generate statement_id starting from the last used ID if the file exists\n",
    "next_statement_id = statement_df['statement_id'].max() + 1 if not statement_df.empty else 1\n",
    "\n",
    "def add_new_statements(statement_df, df, disease_node_df, snv_df, drug_df, start_id):\n",
    "    # Creating lowercase columns for case insensitive comparison\n",
    "    disease_node_df['disease_name_lower'] = disease_node_df['disease_name'].str.lower()\n",
    "    snv_df['gene_variant_lower'] = snv_df['gene'].str.lower() + '_' + snv_df['variant'].str.lower()\n",
    "    drug_df['drug_name_lower'] = drug_df['drug_name'].str.lower()\n",
    "    \n",
    "    # Iterate over the rows of the new data\n",
    "    for index, row in df.iterrows():\n",
    "        # Lookup IDs in the respective dataframes\n",
    "        disease_id = disease_node_df.loc[disease_node_df['disease_name_lower'] == row['disease'].lower(), 'disease_id'].values[0]\n",
    "        snv_id = snv_df.loc[snv_df['gene_variant_lower'] == (row['gene'].lower() + '_' + row['variant'].lower()), 'snv_id'].values[0]\n",
    "        drug_id = drug_df.loc[drug_df['drug_name_lower'] == row['drugs'].lower(), 'drug_id'].values[0]\n",
    "\n",
    "        # Check for unique association and add a new statement if not found\n",
    "        if not ((statement_df['drug_id'] == drug_id) & (statement_df['disease_id'] == disease_id) & (statement_df['snv_id'] == snv_id)).any():\n",
    "            new_entry = {\n",
    "                'statement_id': start_id,\n",
    "                'drug_id': drug_id,\n",
    "                'disease_id': disease_id,\n",
    "                'snv_id': snv_id,\n",
    "                'association': \"\",\n",
    "                'source': 'civic',  # Set source to 'civic' for new entries\n",
    "                'clinical_significance': row['clinical_significance']  # Assume this column exists in df\n",
    "            }\n",
    "            statement_df = statement_df.append(new_entry, ignore_index=True)\n",
    "            start_id += 1\n",
    "        else:\n",
    "            # If the entry already exists, we update 'clinical_significance' and append '+civic' to 'source' if needed\n",
    "            match_idx = (statement_df['drug_id'] == drug_id) & (statement_df['disease_id'] == disease_id) & (statement_df['snv_id'] == snv_id)\n",
    "            statement_df.loc[match_idx, 'clinical_significance'] = row['clinical_significance']  # Assume this column exists in df\n",
    "            # Update source only if 'civic' is not already there\n",
    "            statement_df.loc[match_idx, 'source'] = statement_df.loc[match_idx, 'source'].apply(lambda x: x if 'civic' in x else x + '+civic')\n",
    "    \n",
    "    # Cleanup the DataFrame\n",
    "    disease_node_df.drop(columns=['disease_name_lower'], inplace=True)\n",
    "    snv_df.drop(columns=['gene_variant_lower'], inplace=True)\n",
    "    drug_df.drop(columns=['drug_name_lower'], inplace=True)\n",
    "    \n",
    "    return statement_df\n",
    "\n",
    "# Update or create statement_df with new statements from df\n",
    "statement_df = add_new_statements(statement_df, df, disease_node_df, snv_df, drug_df, next_statement_id)\n",
    "\n",
    "# Save the statement DataFrame\n",
    "statement_df.to_csv(statement_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
